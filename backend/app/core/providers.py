"""LLM Provider Abstraction Layer for Aura."""

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Any


@dataclass
class AuraResponse:
    """Standardized response format for all LLM providers.

    Attributes:
        content: The text generated by the LLM.
        raw_response: The original response object from the provider's SDK.
        usage: A dictionary containing token usage information.
    """

    content: str
    raw_response: Any
    usage: dict[str, int]


class BaseProvider(ABC):
    """Abstract base class for all LLM providers."""

    @abstractmethod
    async def generate(
        self, prompt: str, temperature: float = 0.7, max_tokens: int = 500
    ) -> AuraResponse:
        """Generates content based on a prompt.

        Args:
            prompt: The input text for the LLM.
            temperature: Sampling temperature (0 to 1).
            max_tokens: Maximum number of tokens to generate.

        Returns:
            A standardized AuraResponse object.
        """
        pass


class OllamaProvider(BaseProvider):
    """Local inference using Ollama."""

    def __init__(self, host: str, model: str):
        """Initializes the Ollama provider.

        Args:
            host: The URL of the Ollama server.
            model: The name of the model to use.
        """
        from ollama import Client

        self.client = Client(host=host)
        self.model = model

    async def generate(
        self, prompt: str, temperature: float = 0.7, max_tokens: int = 500
    ) -> AuraResponse:
        """Generates content using Ollama's local API."""
        options = {
            "temperature": temperature,
            "num_predict": max_tokens,
        }
        response = self.client.generate(model=self.model, prompt=prompt, options=options)
        return AuraResponse(
            content=str(response.get("response", "")),
            raw_response=response,
            usage={"total_tokens": response.get("eval_count", 0)},
        )


class GeminiProvider(BaseProvider):
    """Google Gemini API."""

    def __init__(self, api_key: str, model: str = "gemini-2.0-flash"):
        """Initializes the Gemini provider.

        Args:
            api_key: Your Google AI API key.
            model: The Gemini model identifier.
        """
        from google import genai

        self.client = genai.Client(api_key=api_key)
        self.model = model

    async def generate(
        self, prompt: str, temperature: float = 0.7, max_tokens: int = 500
    ) -> AuraResponse:
        """Generates content using Google's GenAI SDK."""
        response = self.client.models.generate_content(
            model=self.model, contents=prompt
        )
        return AuraResponse(
            content=str(response.text) if response.text else "",
            raw_response=response,
            usage={},
        )


class OpenAIProvider(BaseProvider):
    """OpenAI API Provider."""

    def __init__(self, api_key: str, model: str = "gpt-4o"):
        """Initializes the OpenAI provider.

        Args:
            api_key: Your OpenAI API key.
            model: The OpenAI model identifier.
        """
        self.api_key = api_key
        self.model = model

    async def generate(
        self, prompt: str, temperature: float = 0.7, max_tokens: int = 500
    ) -> AuraResponse:
        """Placeholder for OpenAI generation."""
        return AuraResponse(
            content=f"OpenAI ({self.model}) not fully implemented yet.",
            raw_response=None,
            usage={},
        )


class AnthropicProvider(BaseProvider):
    """Anthropic (Claude) API Provider."""

    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-latest"):
        """Initializes the Anthropic provider.

        Args:
            api_key: Your Anthropic API key.
            model: The Claude model identifier.
        """
        self.api_key = api_key
        self.model = model

    async def generate(
        self, prompt: str, temperature: float = 0.7, max_tokens: int = 500
    ) -> AuraResponse:
        """Placeholder for Anthropic generation."""
        return AuraResponse(
            content=f"Anthropic ({self.model}) not fully implemented yet.",
            raw_response=None,
            usage={},
        )
